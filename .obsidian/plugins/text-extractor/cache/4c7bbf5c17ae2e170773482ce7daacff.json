{"path":"DHBW Heidenheim/2024 SoSe/Theoretische Informatik/UnterrichtsMaterial/8.2. Woche Speicherlimitationen Script (1).pdf","text":"Studiengang Informatik Umgang mit Speicherlimitationen Bislang haben wir uns bei der Effizienzanalyse ausschliesslich auf die Laufzeitkosten fokussiert. Ein anderes Effizienzmass ist ebenfalls sehr wichtig: der Speicherbedarf! Wann wichtig? • wenn Speicher knapp ist (Geräte), oder • die Datenmengen sehr gross sind (Big Data)… S. Berninger DHBW Heidenheim Algorithmen sollten möglichst schnell UND speichereffizient sein – aber: Wir müssen darüber nachdenken, ob wir Geschwindigkeit über Speicherverbrauch setzen oder umgekehrt… Studiengang Informatik Big-O-Notation für Speicherbedarf Schlüsselfrage für Zeitkomplexität war: „Wie viele Schritte braucht der Algorithmus bei N Datenelementen?“ Schlüsselfrage für Speicherbedarf: „Wie viele Speichereinheiten braucht der Algorithmus bei N Datenelementen zusätzlich?“ Einfaches Beispiel: Funktion MakeUppercase() bekommt ein Array von Strings und gibt dieses Array zurück - alle Strings konvertiert in CAPS. Das Array [\"fred\", \"anna\", \"oskar\", \"gerda\"] würde konvertiert werden in [\"FRED\", \"ANNA\", \"OSKAR\", \"GERDA\"]. S. Berninger DHBW Heidenheim // existierendes Array um nächsten String verlängern // Array mit erstem String beginnen // String konvertieren Studiengang Informatik Big-O-Notation für Speicherbedarf S. Berninger DHBW Heidenheim Wir bekommen einen Pointer pArray übergeben, und erzeugen eine komplette Kopie dieses Arrays, dessen Adresse wir zurückgeben. -> 2 Arrays belasten den Hauptspeicher: das originale Array und die neu erzeugte Kopie. Da der Gesamtspeicherbedarf proportional zur Menge der Eingangsdaten ist, ist er O (N). Studiengang Informatik Big-O-Notation für Speicherbedarf Speichereffizientere Version (in place): S. Berninger DHBW Heidenheim • Erzeugung keines neuen Arrays, keine sonstigen weiteren Datenelemente: Modifizierung des übergebenen Arrays in place. O(1)-Algorithmus bzgl. Speicherplatz: Zusätzlich benötigter Platz konstant (=0), unabhängig von der Größe des Eingangsarrays! Speichereffizienz ist O (1)! Studiengang Informatik Big-O-Notation für Speicherbedarf Die Berechnung der Speichereffizienz betrachtet nur den Bedarf an zusätzlichem Speicher durch den Algorithmus! Vergleich der beiden Implementierungen: Version Zeitkomplexität Speicherkomplexität Version #1 O(N) O(N) Version #2 O(N) O(1) S. Berninger DHBW Heidenheim Studiengang Informatik Tradeoffs zwischen Zeit und Platz Diese Funktion (in 2 Implementierungen) bekommt ein Array und bestimmt, ob es Duplikate enthält. Zeit: Version #1: Benutzt verschachtelte Schleifen: O (N2) Zeit: Version #2: Benutzt ein Array und nur eine Schleife: O (N) S. Berninger DHBW Heidenheim Studiengang Informatik Trade-Offs zwischen Zeit und Platz Speicherplatz: Version #1: Kein zusätzlicher Speicher: O (1) Speicherplatz: Version #2: erzeugt ein Array mit max. MAXNUM Einträgen: O (M), M = Wertebereich des Arrays S. Berninger DHBW Heidenheim Studiengang Informatik Trade-Offs zwischen Zeit und Platz Version Time complexity Space complexity Version #1 O(N2) O(1) Version #2 O(N) O(M) Version #2: Optimal, wenn Geschwindigkeit nötig ist, und der maximale Wertebereich bekannt und handlebar. Version #1: Optimal, wenn der lokale Speicher knapp oder der Wertebereich sehr gross oder unbekannt ist. S. Berninger DHBW Heidenheim Studiengang Informatik Trade-Offs zwischen Zeit und Platz Version #3: Version Time complexity Space complexity Version #1 O(N2) O(1) Version #2 O(N) O(N) Version #3 O(N logN + N) O(log N) (schnellste Sortierung!) (viele Quicksort-Impl.) -> sehr guter TradeOff zwischen Zeit und Platz! S. Berninger DHBW Heidenheim Studiengang Informatik Sortierung grosser, evtl. externer Datenmengen Bei Sortierung externer Daten kann nicht prinzipiell die gesamte Datenmenge für direkten Zugriff und Vertauschen gleichzeitig in den Speicher geholt werden (Größe nicht limitiert), sondern es müssen Teilmengen als Zwischenschritte sortiert werden können. Divide and Conquer (Teile, Sortiere und Erobere zurück) S. Berninger DHBW Heidenheim Erlaubt zusätzlich Parallelisierung auf mehrere Rechenkerne: 1. Die zu sortierende Datei wird in Teile zerlegt, die jeweils intern sortiert werden können. 2. Die Teile werden parallel sortiert. 3. Das Ergebnis wird aus den sortierten Teilen zusammengemischt: Dazu ist ein Datenelement pro vorsortierter Teilmenge im Speicher ausreichend, das Kleinste wird zum Ergebnis hinzugefügt und durch seinen Nachfolger aus der Ursprungsdatei ersetzt. Studiengang Informatik MergeSort: Sortieren durch Verschmelzen Idee: Teile den Eingangsstapel in zwei möglichst gleich große Teile. Gib jeden Teil einem Helfer mit der Bitte, auch nach dem hier beschriebenen Verfahren vorzugehen. Warte, bis Dir beide sortierte Teile zurückgegeben wurden. Dann durchlaufe beide Stapel gleichzeitig von oben nach unten, und mische die Karten im Reißverschlussprinzip zu einem sortierten Gesamtstapel zusammen. Gib diesen an deinen Auftraggeber zurück. http://panthema.net/2013/sound-of-sorting S. Berninger DHBW Heidenheim Studiengang Informatik MergeSort: Sortieren durch Verschmelzen • Divide & Conquer, vergleichsbasiert • Schnellstes stabiles externes Verfahren, braucht intern nur den Platz zum Mischen S. Berninger DHBW Heidenheim Zeitkomplexität (Worst case) = O(n log(n)) Speicherbedarf: O(n) zusätzlich – nicht in place Parallelisierbar! Studiengang Informatik MergeSort Implementierung S. Berninger DHBW Heidenheim Studiengang Informatik External Memory MergeSort • Einzelne Blöcke werden im Hauptspeicher sortiert und nach dem Sortieren zurückgeschrieben (z.B. in Files) • Die k sortierten Blöcke/ Files werden durch K-Way-Merges gemerged und die Datenelemente sofort zurückgeschrieben S. Berninger DHBW Heidenheim Studiengang Informatik Versteckte Rekursionskosten bzgl. Speicher Einfaches Beispiel: Die Funktion gibt den Countdown einer Zahl auf die Konsole aus. Geschwindigkeit: O (N) Speicherplatz: erzeugt keine neuen Daten. Oder doch? Für den Wert 100 legt die Funktion die 100… 1 auf den Stack, plus jeweils die Rücksprungadresse: O (N). Für alle Rekursionen gilt: Eine Funktion benötigt eine Platzeinheit für jeden rekursiven Aufruf. Die Stacklimits sind sehr eng! Mein Notebook bricht den Countdown der Zahlen ab 50.000 bei 1.733 ab, und terminiert mit “RangeError: Maximum call stack size exceeded”! S. Berninger DHBW Heidenheim Studiengang Informatik Versteckte Rekursionskosten Ansatz mit einfacher Schleife: Die Funktion gibt den Countdown einer Zahl auf die Konsole aus. Geschwindigkeit: O (N) Platz: O (N) O(1) Quicksort: Platzbedarf: O (log N), weil es log N rekursive Aufrufe macht, und die Stacktiefe von log N benötigt! S. Berninger DHBW Heidenheim Studiengang Informatik Speicherbedarf von Sortieralgorithmen INTERN vs. EXTERN IN PLACE/ INTERN Alle Datenelemente sind im Zugriff/ bekannt. EXTERN Nur ein Teil der Daten ist zu einem Zeitpunkt bekannt. • Alle Daten passen in den Speicher • Datensätze zu groß für Hauptspeicher • Algorithmus findet auf dem Hauptspeicher statt • Aufteilung der Daten auf externe Speichermedien S. Berninger DHBW Heidenheim Studiengang Informatik Sortierverfahren ohne Vergleiche CountingSort: Sortieren durch Auszählen Nichtvergleichendes Sortieren in Linearzeit (O(N)) Wertebereich: natürliche Zahlen, begrenztes Intervall (Alter, Distanzen, …) Idee: Bestimme in einem Arbeitsarray (Hashtabelle) C[0..k] für jeden Index die Anzahl der Schlüssel A, die diesem Index entsprechen. Dann plaziere direkt jedes Element, das dem nächsten Index entspricht, (in einer Schleife) in die richtige Stelle in B. Zielgruppe: kleiner Wertebereich –> kleiner Platzbedarf (Platzbedarf nur abhängig vom Intervall), geringe Laufzeit Nachteil: Sortierung kompositer Daten möglich, aber sehr viel langsamer durch zusätzliche Suche des n. Elements S. Berninger DHBW Heidenheim Studiengang Informatik Sortierverfahren ohne Vergleiche CountingSort: Sortieren durch Auszählen Zeitkomplexität: O(n + k) Speicherbedarf: O(k) S. Berninger DHBW Heidenheim Studiengang Informatik Zusammenfassung Wir haben gelernt, die Effizienz eines Algorithmus bzgl Zeit und Platzbedarf zu bestimmen. Dadurch können wir unterschliedliche Verfahren und unterschiedliche Implementierungen des gleichen Algorithmus miteinander vergleichen. S. Berninger DHBW Heidenheim Studiengang Informatik Komplexität von Sortierverfahren … S. Berninger DHBW Heidenheim Verfahren Zeitbedarf Platzbedarf Stabilität Eher geeignet für Arrays Eher geeignet für Listen Geeignet für externe DatenWorst case Average case BubbleSort O (n2) O (n2) O (1) ja x nein SelectionSort O (n2) O (n2) O (1) (nein) x nein InsertionSort O (n2) O (n2) O (1) ja x nein QuickSort O (n2) O (n log n) O (log n) (nein) x ja Mergesort O (n log n) O (n log n) O (n) ja x ja CountingSort O (n + k) O (n + k) O (n + k) ja x (ja) Studiengang Informatik Übungen in BigBlueButton 1. Beschreiben Sie die Speicherplatz-Komplexität des “Word Builder”-Algorithmus mit Hilfe von Big O. Der Algorithmus erzeugt jede Kombination einzelner Zeichen zu Strings aus 2 Zeichen. Bekommen wir z.B. das Array [\"a\", \"b\", \"c\", \"d\"], würden wir ein neues Array zurückgeben, das folgende Stringkombinationen enthält: ['ab', 'ac', 'ad', 'ba', 'bc', 'bd‘, 'ca', 'cb', 'cd', 'da', 'db', 'dc‘] Antworten: A O (1) B O (log N) C O (N) D O (N*logN) E O (N2) S. Berninger DHBW Heidenheim Studiengang Informatik Übung 2. Diese Funktion kehrt einen String um. Beschreiben Sie ihre Speicherplatz-Komplexität mit Hilfe von Big O: Antworten: A O (1) B O (log N) C O (N) D O (N*logN) E O (N2) S. Berninger DHBW Heidenheim Studiengang Informatik Übung 3. Gegeben sind 3 verschiedene Implementierungen einer Funktion, die ein Array von Zahlen bekommt und ein Array der verdoppelten Zahlen zurückgibt. Für den Input [5, 4, 3, 2, 1] wäre der Ouput: [10, 8, 6, 4, 2]. Die Speicherplatzkomplexität von Version #1 ist: A O (1) B O (log N) C O (N) D O (N*logN) E O (N2) S. Berninger DHBW Heidenheim Studiengang Informatik Übungen 3. Gegeben sind 3 verschiedene Implementierungen einer Funktion, die ein Array von Zahlen bekommt und ein Array der verdoppelten Zahlen zurückgibt. Für den Input [5, 4, 3, 2, 1] wäre der Ouput: [10, 8, 6, 4, 2]. Die Speicherplatzkomplexität von Version #2 ist: A O (1) B O (log N) C O (N) D O (N*logN) E O (N2) S. Berninger DHBW Heidenheim Studiengang Informatik Übungen 3. Gegeben sind 3 verschiedene Implementierungen einer Funktion, die ein Array von Zahlen bekommt und ein Array der verdoppelten Zahlen zurückgibt. Für den Input [5, 4, 3, 2, 1] wäre der Ouput: [10, 8, 6, 4, 2]. Die Speicherplatzkomplexität von Version #3 ist: A O (1) B O (log N) C O (N) D O (N*logN) E O (N2) S. Berninger DHBW Heidenheim","libVersion":"0.3.2","langs":""}